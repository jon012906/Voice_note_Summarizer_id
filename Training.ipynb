{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c879a7",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7a4ad1-b6d3-4947-a326-f52ce2b63ac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:20.877641Z",
     "iopub.status.busy": "2025-05-19T23:52:20.877354Z",
     "iopub.status.idle": "2025-05-19T23:52:31.808245Z",
     "shell.execute_reply": "2025-05-19T23:52:31.807441Z",
     "shell.execute_reply.started": "2025-05-19T23:52:20.877619Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: audiomentations==0.41.0 in /usr/local/lib/python3.11/dist-packages (0.41.0)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
      "Requirement already satisfied: numpy-minmax in /usr/local/lib/python3.11/dist-packages (0.4.0)\n",
      "Requirement already satisfied: numpy-rms in /usr/local/lib/python3.11/dist-packages (0.5.0)\n",
      "Requirement already satisfied: python-stretch in /usr/local/lib/python3.11/dist-packages (0.3.1)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.5.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.13.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from numpy-minmax) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.0->numpy-minmax) (2.22)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (25.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.4.26)\n",
      "Requirement already satisfied: jiwer in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /usr/local/lib/python3.11/dist-packages (from jiwer) (3.13.0)\n",
      "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.31.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.11.18)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install audiomentations==0.41.0 --no-dependencies\n",
    "# !pip install librosa numpy-minmax numpy-rms python-stretch\n",
    "# !pip install jiwer\n",
    "# !pip install evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fb09aeef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:31.810047Z",
     "iopub.status.busy": "2025-05-19T23:52:31.809800Z",
     "iopub.status.idle": "2025-05-19T23:52:31.815115Z",
     "shell.execute_reply": "2025-05-19T23:52:31.814433Z",
     "shell.execute_reply.started": "2025-05-19T23:52:31.810024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, Audio, load_dataset\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab5f6bcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:31.815917Z",
     "iopub.status.busy": "2025-05-19T23:52:31.815731Z",
     "iopub.status.idle": "2025-05-19T23:52:31.830075Z",
     "shell.execute_reply": "2025-05-19T23:52:31.829360Z",
     "shell.execute_reply.started": "2025-05-19T23:52:31.815903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0+cu124\n",
      "CUDA version: 12.4\n",
      "CUDA available: True\n",
      "CUDA device: Tesla T4\n",
      "GPU Memory: 15.83 GB\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA\")\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\") if torch.cuda.is_available() else print(\"No GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "074bfe23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:31.832369Z",
     "iopub.status.busy": "2025-05-19T23:52:31.831802Z",
     "iopub.status.idle": "2025-05-19T23:52:31.843870Z",
     "shell.execute_reply": "2025-05-19T23:52:31.843198Z",
     "shell.execute_reply.started": "2025-05-19T23:52:31.832352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"NUMPY_EXPERIMENTAL_ARRAY_FUNCTION\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efa81011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:31.844741Z",
     "iopub.status.busy": "2025-05-19T23:52:31.844480Z",
     "iopub.status.idle": "2025-05-19T23:52:31.859385Z",
     "shell.execute_reply": "2025-05-19T23:52:31.858711Z",
     "shell.execute_reply.started": "2025-05-19T23:52:31.844724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d488f8db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:31.860471Z",
     "iopub.status.busy": "2025-05-19T23:52:31.860211Z",
     "iopub.status.idle": "2025-05-19T23:52:31.876886Z",
     "shell.execute_reply": "2025-05-19T23:52:31.876199Z",
     "shell.execute_reply.started": "2025-05-19T23:52:31.860449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Adjust these based on your hardware constraints:\n",
    "MODEL_SIZE = \"small\"\n",
    "MAX_AUDIO_LENGTH = 15.0 \n",
    "BATCH_SIZE = 16  \n",
    "GRADIENT_ACCUMULATION = 2  \n",
    "USE_AUGMENTATION = True \n",
    "NUM_PROC = None\n",
    "model_checkpoint = f\"openai/whisper-{MODEL_SIZE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec69abd",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9aacc65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:31.877896Z",
     "iopub.status.busy": "2025-05-19T23:52:31.877620Z",
     "iopub.status.idle": "2025-05-19T23:52:31.943090Z",
     "shell.execute_reply": "2025-05-19T23:52:31.942537Z",
     "shell.execute_reply.started": "2025-05-19T23:52:31.877874Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4970\n",
      "Validation set size: 3349\n"
     ]
    }
   ],
   "source": [
    "dataset_root = \"/kaggle/input/common-voice-ds/cv-corpus-17.0-2024-03-15/id\"\n",
    "clips_dir = os.path.join(dataset_root, \"clips\")\n",
    "train_tsv = os.path.join(dataset_root, \"train.tsv\")\n",
    "dev_tsv = os.path.join(dataset_root, \"dev.tsv\")\n",
    "\n",
    "# Load the TSV files into pandas DataFrames\n",
    "train_df = pd.read_csv(train_tsv, sep='\\t')\n",
    "dev_df = pd.read_csv(dev_tsv, sep='\\t')\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Validation set size: {len(dev_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bba9825f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:31.944323Z",
     "iopub.status.busy": "2025-05-19T23:52:31.943857Z",
     "iopub.status.idle": "2025-05-19T23:52:31.948867Z",
     "shell.execute_reply": "2025-05-19T23:52:31.948177Z",
     "shell.execute_reply.started": "2025-05-19T23:52:31.944306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def create_dataset_from_df(df, clips_dir):\n",
    "    # Get the full paths to audio files\n",
    "    audio_paths = [os.path.join(clips_dir, filename) for filename in df['path'].values]\n",
    "    \n",
    "    # Create a dictionary with our data\n",
    "    dataset_dict = {\n",
    "        \"audio\": audio_paths,\n",
    "        \"sentence\": df['sentence'].values,\n",
    "        \"path\": df['path'].values,\n",
    "    }\n",
    "    \n",
    "    # Create a Hugging Face Dataset\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    \n",
    "    # Add audio feature\n",
    "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32013914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:52:31.949777Z",
     "iopub.status.busy": "2025-05-19T23:52:31.949531Z",
     "iopub.status.idle": "2025-05-19T23:53:28.979576Z",
     "shell.execute_reply": "2025-05-19T23:53:28.978968Z",
     "shell.execute_reply.started": "2025-05-19T23:52:31.949752Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1811f2c0265a4f65b779887051a8fde0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4970 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6817eefd4ff0448f895d6edc14de794d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/3349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set after filtering: 4970 examples\n",
      "Validation set after filtering: 3349 examples\n"
     ]
    }
   ],
   "source": [
    "train_dataset = create_dataset_from_df(train_df, clips_dir)\n",
    "eval_dataset = create_dataset_from_df(dev_df, clips_dir)\n",
    "\n",
    "# Filter out examples that don't have transcriptions\n",
    "train_dataset = train_dataset.filter(lambda example: example[\"sentence\"] is not None)\n",
    "eval_dataset = eval_dataset.filter(lambda example: example[\"sentence\"] is not None)\n",
    "\n",
    "print(f\"Training set after filtering: {len(train_dataset)} examples\")\n",
    "print(f\"Validation set after filtering: {len(eval_dataset)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f55864",
   "metadata": {},
   "source": [
    "# Prepare Feature Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cb31109e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:53:28.982598Z",
     "iopub.status.busy": "2025-05-19T23:53:28.982322Z",
     "iopub.status.idle": "2025-05-19T23:53:29.999100Z",
     "shell.execute_reply": "2025-05-19T23:53:29.998510Z",
     "shell.execute_reply.started": "2025-05-19T23:53:28.982581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(model_checkpoint)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b186a7a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:53:29.999919Z",
     "iopub.status.busy": "2025-05-19T23:53:29.999742Z",
     "iopub.status.idle": "2025-05-19T23:53:30.335178Z",
     "shell.execute_reply": "2025-05-19T23:53:30.334631Z",
     "shell.execute_reply.started": "2025-05-19T23:53:29.999905Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e9ed6",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169bd3da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:53:30.336066Z",
     "iopub.status.busy": "2025-05-19T23:53:30.335861Z",
     "iopub.status.idle": "2025-05-19T23:53:30.340207Z",
     "shell.execute_reply": "2025-05-19T23:53:30.339556Z",
     "shell.execute_reply.started": "2025-05-19T23:53:30.336050Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "augment_waveform = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.005, max_amplitude=0.015, p=0.3),\n",
    "    TimeStretch(min_rate=0.9, max_rate=1.25, p=0.3, leave_length_unchanged=False),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.3)\n",
    "    ,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21d3ea23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:53:30.341541Z",
     "iopub.status.busy": "2025-05-19T23:53:30.340873Z",
     "iopub.status.idle": "2025-05-19T23:57:59.175284Z",
     "shell.execute_reply": "2025-05-19T23:57:59.174336Z",
     "shell.execute_reply.started": "2025-05-19T23:53:30.341524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a818f23c9e46cdba15b06551024ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4970 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/audiomentations/core/transforms_interface.py:107: UserWarning: Warning: input samples dtype is np.float64. Converting to np.float32\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd17b4d7a1c8476c9fbd7caa97b1245c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3349 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prepare_dataset(batch, apply_augmentation=False):\n",
    "    # Process audio data\n",
    "    audio = batch[\"audio\"]\n",
    "    array = batch[\"audio\"][\"array\"]\n",
    "\n",
    "    if apply_augmentation:\n",
    "        # Apply your augmentations here\n",
    "        array = augment_waveform(samples=array, sample_rate=16000)\n",
    "    # Extract features\n",
    "    input_features = processor(\n",
    "        array, \n",
    "        sampling_rate=audio[\"sampling_rate\"],\n",
    "        return_tensors=\"pt\"\n",
    "    ).input_features[0]\n",
    "    \n",
    "    # Tokenize text\n",
    "    labels = processor.tokenizer(batch[\"sentence\"]).input_ids\n",
    "    \n",
    "    return {\"input_features\": input_features, \"labels\": labels}\n",
    "\n",
    "# Map the preparation function to our datasets\n",
    "train_dataset = train_dataset.map(lambda batch: prepare_dataset(batch, apply_augmentation=True), remove_columns=train_dataset.column_names)\n",
    "eval_dataset = eval_dataset.map(lambda batch: prepare_dataset(batch, apply_augmentation=False), remove_columns=eval_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e8cbb524",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:57:59.176427Z",
     "iopub.status.busy": "2025-05-19T23:57:59.176132Z",
     "iopub.status.idle": "2025-05-19T23:57:59.183306Z",
     "shell.execute_reply": "2025-05-19T23:57:59.182531Z",
     "shell.execute_reply.started": "2025-05-19T23:57:59.176404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Any, Dict, List, Union\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # Extract input_features and labels\n",
    "        input_features = [feature[\"input_features\"] for feature in features]\n",
    "        label_features = [feature[\"labels\"] for feature in features]\n",
    "\n",
    "        # Pad input features using the feature extractor\n",
    "        batch = {\n",
    "            \"input_features\": torch.nn.utils.rnn.pad_sequence(\n",
    "                [torch.tensor(f) for f in input_features], batch_first=True\n",
    "            )\n",
    "        }\n",
    "\n",
    "        # Pad labels using the tokenizer\n",
    "        labels_batch = self.processor.tokenizer.pad(\n",
    "            [{\"input_ids\": l} for l in label_features],\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Replace padding token id's with -100 to ignore in loss computation\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e10ec9f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:57:59.184431Z",
     "iopub.status.busy": "2025-05-19T23:57:59.184094Z",
     "iopub.status.idle": "2025-05-19T23:57:59.203073Z",
     "shell.execute_reply": "2025-05-19T23:57:59.202390Z",
     "shell.execute_reply.started": "2025-05-19T23:57:59.184405Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir = f\"/kaggle/working/{model_checkpoint}-indonesian\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d053af",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be2c0299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:57:59.219041Z",
     "iopub.status.busy": "2025-05-19T23:57:59.218880Z",
     "iopub.status.idle": "2025-05-19T23:57:59.987702Z",
     "shell.execute_reply": "2025-05-19T23:57:59.987198Z",
     "shell.execute_reply.started": "2025-05-19T23:57:59.219028Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fe3f4aadaff462f926c98f38c2d5739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a4268cdf004d3694fb63227b9de190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b71913",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:57:59.988548Z",
     "iopub.status.busy": "2025-05-19T23:57:59.988336Z",
     "iopub.status.idle": "2025-05-19T23:57:59.993220Z",
     "shell.execute_reply": "2025-05-19T23:57:59.992247Z",
     "shell.execute_reply.started": "2025-05-19T23:57:59.988523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = 100 * cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\": cer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9996f",
   "metadata": {},
   "source": [
    "# Load pre-trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8fd559c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:57:59.994775Z",
     "iopub.status.busy": "2025-05-19T23:57:59.994105Z",
     "iopub.status.idle": "2025-05-19T23:58:00.012254Z",
     "shell.execute_reply": "2025-05-19T23:58:00.011746Z",
     "shell.execute_reply.started": "2025-05-19T23:57:59.994751Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e201a8e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:58:00.013055Z",
     "iopub.status.busy": "2025-05-19T23:58:00.012892Z",
     "iopub.status.idle": "2025-05-19T23:58:00.025536Z",
     "shell.execute_reply": "2025-05-19T23:58:00.025019Z",
     "shell.execute_reply.started": "2025-05-19T23:58:00.013034Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251443d4",
   "metadata": {},
   "source": [
    "# Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce578f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:58:00.026372Z",
     "iopub.status.busy": "2025-05-19T23:58:00.026182Z",
     "iopub.status.idle": "2025-05-19T23:58:00.070896Z",
     "shell.execute_reply": "2025-05-19T23:58:00.070407Z",
     "shell.execute_reply.started": "2025-05-19T23:58:00.026358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=BATCH_SIZE//2,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=1500,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_steps=500,\n",
    "    logging_steps=50,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    "    generation_max_length=225,\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cffb114d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:58:00.071690Z",
     "iopub.status.busy": "2025-05-19T23:58:00.071491Z",
     "iopub.status.idle": "2025-05-19T23:58:00.438032Z",
     "shell.execute_reply": "2025-05-19T23:58:00.437509Z",
     "shell.execute_reply.started": "2025-05-19T23:58:00.071675Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35/810305443.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.tokenizer,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149c55e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15366085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-19T23:58:00.438928Z",
     "iopub.status.busy": "2025-05-19T23:58:00.438729Z",
     "iopub.status.idle": "2025-05-20T08:24:25.046380Z",
     "shell.execute_reply": "2025-05-20T08:24:25.045144Z",
     "shell.execute_reply.started": "2025-05-19T23:58:00.438913Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1002' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1002/1500 8:25:38 < 4:11:48, 0.03 it/s, Epoch 6.42/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "      <th>Cer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.388132</td>\n",
       "      <td>40.672961</td>\n",
       "      <td>14.528497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.437587</td>\n",
       "      <td>38.247796</td>\n",
       "      <td>13.814474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py:3339: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 448, 'suppress_tokens': [], 'begin_suppress_tokens': [220, 50257]}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/3956863919.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m      \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m      \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-final'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training completed successfully!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2245\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2246\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2558\u001b[0m                     )\n\u001b[1;32m   2559\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2560\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2562\u001b[0m                     if (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3780\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale_wrt_gas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3782\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3784\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_lomo_optimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlomo_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "     print(\"Starting training...\")\n",
    "     trainer.train()\n",
    "     model.save_pretrained(os.path.join(output_dir,'-final'))\n",
    "     print(\"Training completed successfully!\")\n",
    "     \n",
    "     trainer.save_model()\n",
    "     print(f\"Model saved to {training_args.output_dir}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Training error: {str(e)}\")\n",
    "    try:\n",
    "        trainer.save_model(\"./checkpoint-error\")\n",
    "        print(\"Saved model checkpoint despite error\")\n",
    "    except:\n",
    "        print(\"Could not save checkpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4462d9",
   "metadata": {},
   "source": [
    "Error happened due to stopping the training midway because of time constraint on the session runtime"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7462922,
     "sourceId": 11874943,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "speech_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
