{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8c879a7",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb09aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import DatasetDict, Dataset, concatenate_datasets, Audio\n",
    "import torchaudio\n",
    "import torch\n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, Shift\n",
    "import evaluate\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9f78c",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da77a411",
   "metadata": {},
   "source": [
    "#### Edit Librovox Csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "092f0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_train = \"./librivox-indonesia/data/train/metadata_train.csv\" \n",
    "base_path_test = \"./librivox-indonesia/data/test/metadata_test.csv\" \n",
    "lib_train = pd.read_csv(base_path_train)\n",
    "lib_test = pd.read_csv(base_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d28171e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>language</th>\n",
       "      <th>reader</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/sundanese/universal-declaration-of-human...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>pernyataan umum ngeunaan hak hak asasi manusa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/sundanese/universal-declaration-of-human...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>gubragna ka alam dunya teh bari nampa hak hak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/sundanese/universal-declaration-of-human...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>kalawan dibarung ku ayana kabebasan anu fundam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/sundanese/universal-declaration-of-human...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>perserikatan bangsa bangsa boga komitmen pikeu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/sundanese/universal-declaration-of-human...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>ieu komitmen teh awalna lahir dina piagem pers...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path language  reader  \\\n",
       "0  train/sundanese/universal-declaration-of-human...      sun    3174   \n",
       "1  train/sundanese/universal-declaration-of-human...      sun    3174   \n",
       "2  train/sundanese/universal-declaration-of-human...      sun    3174   \n",
       "3  train/sundanese/universal-declaration-of-human...      sun    3174   \n",
       "4  train/sundanese/universal-declaration-of-human...      sun    3174   \n",
       "\n",
       "                                            sentence  \n",
       "0  pernyataan umum ngeunaan hak hak asasi manusa ...  \n",
       "1  gubragna ka alam dunya teh bari nampa hak hak ...  \n",
       "2  kalawan dibarung ku ayana kabebasan anu fundam...  \n",
       "3  perserikatan bangsa bangsa boga komitmen pikeu...  \n",
       "4  ieu komitmen teh awalna lahir dina piagem pers...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56232fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>language</th>\n",
       "      <th>reader</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test/sundanese/universal-declaration-of-human-...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>mun inget kana ieu pernyataan rek satekah pola...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test/sundanese/universal-declaration-of-human-...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>asal usul kabangsaan atawa kamasarakatan  hak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test/sundanese/universal-declaration-of-human-...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>sacara gembleng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test/sundanese/universal-declaration-of-human-...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>pon kitu deui dipahing nibankeun hukuman leuwi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test/sundanese/universal-declaration-of-human-...</td>\n",
       "      <td>sun</td>\n",
       "      <td>3174</td>\n",
       "      <td>pasal lima belas sing saha bae boga hak dina n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path language  reader  \\\n",
       "0  test/sundanese/universal-declaration-of-human-...      sun    3174   \n",
       "1  test/sundanese/universal-declaration-of-human-...      sun    3174   \n",
       "2  test/sundanese/universal-declaration-of-human-...      sun    3174   \n",
       "3  test/sundanese/universal-declaration-of-human-...      sun    3174   \n",
       "4  test/sundanese/universal-declaration-of-human-...      sun    3174   \n",
       "\n",
       "                                            sentence  \n",
       "0  mun inget kana ieu pernyataan rek satekah pola...  \n",
       "1  asal usul kabangsaan atawa kamasarakatan  hak ...  \n",
       "2                                    sacara gembleng  \n",
       "3  pon kitu deui dipahing nibankeun hukuman leuwi...  \n",
       "4  pasal lima belas sing saha bae boga hak dina n...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39d412fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib_train = lib_train[lib_train['language'] == 'ind']\n",
    "lib_train = lib_train.drop(columns=['reader'], axis=1)\n",
    "lib_test = lib_test[lib_test['language'] == 'id']\n",
    "lib_test = lib_test.drop(columns=['reader'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a378ee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>test/indonesian/mengelilingi-doenia-dalam-80-h...</td>\n",
       "      <td>id</td>\n",
       "      <td>perdjalanannja itoe seolah olah seperti seboea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>test/indonesian/mengelilingi-doenia-dalam-80-h...</td>\n",
       "      <td>id</td>\n",
       "      <td>sampailah ia keroemah reform club di pall mall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>test/indonesian/mengelilingi-doenia-dalam-80-h...</td>\n",
       "      <td>id</td>\n",
       "      <td>makanan paginja itoe jaitoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>test/indonesian/mengelilingi-doenia-dalam-80-h...</td>\n",
       "      <td>id</td>\n",
       "      <td>makanan itoe matjamnja sama djoega dengan maka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>test/indonesian/mengelilingi-doenia-dalam-80-h...</td>\n",
       "      <td>id</td>\n",
       "      <td>djadi pentjoerinja diketahoei orang tanda tand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path language  \\\n",
       "151  test/indonesian/mengelilingi-doenia-dalam-80-h...       id   \n",
       "152  test/indonesian/mengelilingi-doenia-dalam-80-h...       id   \n",
       "153  test/indonesian/mengelilingi-doenia-dalam-80-h...       id   \n",
       "154  test/indonesian/mengelilingi-doenia-dalam-80-h...       id   \n",
       "155  test/indonesian/mengelilingi-doenia-dalam-80-h...       id   \n",
       "\n",
       "                                              sentence  \n",
       "151  perdjalanannja itoe seolah olah seperti seboea...  \n",
       "152     sampailah ia keroemah reform club di pall mall  \n",
       "153                        makanan paginja itoe jaitoe  \n",
       "154  makanan itoe matjamnja sama djoega dengan maka...  \n",
       "155  djadi pentjoerinja diketahoei orang tanda tand...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f106f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>language</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>train/indonesian/mengelilingi-doenia-dalam-80-...</td>\n",
       "      <td>ind</td>\n",
       "      <td>bab jang ketiga peri meriwajatkan pertjakapan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>train/indonesian/mengelilingi-doenia-dalam-80-...</td>\n",
       "      <td>ind</td>\n",
       "      <td>djam poekoel setengah doea belas phileas fogg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>train/indonesian/mengelilingi-doenia-dalam-80-...</td>\n",
       "      <td>ind</td>\n",
       "      <td>setelah lima ratoes toedjoeh poeloeh lima kali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>train/indonesian/mengelilingi-doenia-dalam-80-...</td>\n",
       "      <td>ind</td>\n",
       "      <td>jaitoe seboeah roemah jang telah didirikan den...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>train/indonesian/mengelilingi-doenia-dalam-80-...</td>\n",
       "      <td>ind</td>\n",
       "      <td>phileas fogg teroes menoedjoe kekamar makan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   path language  \\\n",
       "1426  train/indonesian/mengelilingi-doenia-dalam-80-...      ind   \n",
       "1427  train/indonesian/mengelilingi-doenia-dalam-80-...      ind   \n",
       "1428  train/indonesian/mengelilingi-doenia-dalam-80-...      ind   \n",
       "1429  train/indonesian/mengelilingi-doenia-dalam-80-...      ind   \n",
       "1430  train/indonesian/mengelilingi-doenia-dalam-80-...      ind   \n",
       "\n",
       "                                               sentence  \n",
       "1426  bab jang ketiga peri meriwajatkan pertjakapan ...  \n",
       "1427  djam poekoel setengah doea belas phileas fogg ...  \n",
       "1428  setelah lima ratoes toedjoeh poeloeh lima kali...  \n",
       "1429  jaitoe seboeah roemah jang telah didirikan den...  \n",
       "1430        phileas fogg teroes menoedjoe kekamar makan  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3fc642b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_train_name = \"id_metadata_train.csv\"\n",
    "csv_test_name = \"id_metadata_test.csv\"\n",
    "lib_train.to_csv(csv_train_name)\n",
    "lib_test.to_csv(csv_test_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec69abd",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76493bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 4970\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 3349\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 3641\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load common-voice dataset\n",
    "# Path configuration\n",
    "base_path = \"./\"\n",
    "cv_path = os.path.join(base_path, \"cv-corpus-17.0-2024-03-15\\id\")\n",
    "\n",
    "# Load TSV files\n",
    "def load_cv_split(split):\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(cv_path, f\"{split}.tsv\"),\n",
    "        sep=\"\\t\",\n",
    "        usecols=[\"path\", \"sentence\", \"client_id\"]\n",
    "    )\n",
    "    df[\"audio\"] = df[\"path\"].apply(\n",
    "        lambda x: os.path.join(cv_path, \"clips\", x)\n",
    "    )\n",
    "    df = df.drop(columns=[\"client_id\", \"path\"])\n",
    "    sentence = df.pop(\"sentence\")\n",
    "    df[\"text\"] = sentence\n",
    "    return Dataset.from_pandas(df).cast_column(\"audio\", Audio())\n",
    "\n",
    "common_voice = DatasetDict({\n",
    "    \"train\": load_cv_split(\"train\"),\n",
    "    \"validation\": load_cv_split(\"dev\"),\n",
    "    \"test\": load_cv_split(\"test\")\n",
    "})\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f42b3450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': None, 'path': './cv-corpus-17.0-2024...</td>\n",
       "      <td>Saya mendengarkan cerita membosankan dari tema...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': None, 'path': './cv-corpus-17.0-2024...</td>\n",
       "      <td>halo dunia!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': None, 'path': './cv-corpus-17.0-2024...</td>\n",
       "      <td>Sudah makan? sudah sholat...?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': None, 'path': './cv-corpus-17.0-2024...</td>\n",
       "      <td>mau pergi kemana hari ini?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': None, 'path': './cv-corpus-17.0-2024...</td>\n",
       "      <td>udah keluar hasil testnya?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  {'bytes': None, 'path': './cv-corpus-17.0-2024...   \n",
       "1  {'bytes': None, 'path': './cv-corpus-17.0-2024...   \n",
       "2  {'bytes': None, 'path': './cv-corpus-17.0-2024...   \n",
       "3  {'bytes': None, 'path': './cv-corpus-17.0-2024...   \n",
       "4  {'bytes': None, 'path': './cv-corpus-17.0-2024...   \n",
       "\n",
       "                                                text  \n",
       "0  Saya mendengarkan cerita membosankan dari tema...  \n",
       "1                                        halo dunia!  \n",
       "2                      Sudah makan? sudah sholat...?  \n",
       "3                         mau pergi kemana hari ini?  \n",
       "4                         udah keluar hasil testnya?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_voice['train'].select(range(5)).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef5fdce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 5635\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 603\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load Librivox dataset\n",
    "\n",
    "def load_librivox_split(base_path: str, split: str) -> Dataset:\n",
    "    \"\"\"Load and process a single split (train/test)\"\"\"\n",
    "    \n",
    "    # Load metadata CSV\n",
    "    csv_path = os.path.join(base_path, split, f\"id_metadata_{split}.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Construct full audio paths\n",
    "    df[\"full_audio_path\"] = df[\"audio_path\"].apply(\n",
    "        lambda x: os.path.join(base_path, x)\n",
    "    )\n",
    "    \n",
    "    # Verify files exist\n",
    "    df = df[df[\"full_audio_path\"].apply(os.path.exists)]\n",
    "    \n",
    "    # Create dataset with proper columns\n",
    "    return Dataset.from_pandas(df[[\"full_audio_path\", \"transcription\"]]).rename_columns({\n",
    "        \"full_audio_path\": \"audio\",\n",
    "        \"transcription\": \"text\"\n",
    "    }).cast_column(\"audio\", Audio())\n",
    "\n",
    "# Configuration\n",
    "BASE_PATH = \"./librivox-indonesia/data\"\n",
    "\n",
    "# Create DatasetDict\n",
    "librivox_dataset = DatasetDict({\n",
    "    \"train\": load_librivox_split(BASE_PATH, \"train\"),\n",
    "    \"test\": load_librivox_split(BASE_PATH, \"test\")\n",
    "})\n",
    "\n",
    "# Verify structure\n",
    "print(\"Dataset structure:\", librivox_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba515d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': None, 'path': './librivox-indonesia/...</td>\n",
       "      <td>bab jang ketiga peri meriwajatkan pertjakapan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': None, 'path': './librivox-indonesia/...</td>\n",
       "      <td>djam poekoel setengah doea belas phileas fogg ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': None, 'path': './librivox-indonesia/...</td>\n",
       "      <td>setelah lima ratoes toedjoeh poeloeh lima kali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': None, 'path': './librivox-indonesia/...</td>\n",
       "      <td>jaitoe seboeah roemah jang telah didirikan den...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': None, 'path': './librivox-indonesia/...</td>\n",
       "      <td>phileas fogg teroes menoedjoe kekamar makan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  {'bytes': None, 'path': './librivox-indonesia/...   \n",
       "1  {'bytes': None, 'path': './librivox-indonesia/...   \n",
       "2  {'bytes': None, 'path': './librivox-indonesia/...   \n",
       "3  {'bytes': None, 'path': './librivox-indonesia/...   \n",
       "4  {'bytes': None, 'path': './librivox-indonesia/...   \n",
       "\n",
       "                                                text  \n",
       "0  bab jang ketiga peri meriwajatkan pertjakapan ...  \n",
       "1  djam poekoel setengah doea belas phileas fogg ...  \n",
       "2  setelah lima ratoes toedjoeh poeloeh lima kali...  \n",
       "3  jaitoe seboeah roemah jang telah didirikan den...  \n",
       "4        phileas fogg teroes menoedjoe kekamar makan  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "librivox_dataset['train'].select(range(5)).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f55864",
   "metadata": {},
   "source": [
    "# Prepare Feature Extractor, Tokenizer and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb31109e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JonLimanza\\anaconda3\\envs\\speech_recognition\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import WhisperFeatureExtractor, WhisperTokenizer, WhisperProcessor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-medium\", language=\"Indonesian\", task=\"transcribe\")\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-medium\", language=\"Indonesian\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e9ed6",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8cbb524",
   "metadata": {},
   "outputs": [],
   "source": [
    "librivox_dataset = librivox_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "common_voice = common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed06a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "do_lower_case = False\n",
    "do_remove_punctuation = False\n",
    "\n",
    "normalizer = BasicTextNormalizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c79df",
   "metadata": {},
   "source": [
    "Audiomentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "169bd3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_waveform = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.005, max_amplitude=0.015, p=0.3),\n",
    "    TimeStretch(min_rate=0.9, max_rate=1.25, p=0.3, leave_length_unchanged=False),\n",
    "    PitchShift(min_semitones=-4, max_semitones=4, p=0.3)\n",
    "    ,])\n",
    "\n",
    "def augment_dataset(batch):\n",
    "\n",
    "    audio = batch[\"audio\"][\"array\"]\n",
    "    # apply augmentation\n",
    "    augmented_audio = augment_waveform(samples=audio, sample_rate=16000)\n",
    "\n",
    "    batch[\"audio\"][\"array\"] = augmented_audio\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "425901c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "    # load and (possibly) resample audio data to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = processor.feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "    # compute input length of audio sample in seconds\n",
    "    batch[\"input_length\"] = len(audio[\"array\"]) / audio[\"sampling_rate\"]\n",
    "    \n",
    "    # optional pre-processing steps\n",
    "    transcription = batch[\"transcription\"]\n",
    "    if do_lower_case:\n",
    "        transcription = transcription.lower()\n",
    "    if do_remove_punctuation:\n",
    "        transcription = normalizer(transcription).strip()\n",
    "    \n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = processor.tokenizer(transcription).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef2784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/4970 [00:00<?, ? examples/s]"
     ]
    }
   ],
   "source": [
    "# Ensure compatibility with NumPy and resolve potential LLVM issues\n",
    "os.environ[\"NUMPY_EXPERIMENTAL_ARRAY_FUNCTION\"] = \"0\"\n",
    "\n",
    "# Apply augmentation to datasets\n",
    "common_voice['train'] = common_voice['train'].map(augment_dataset, num_proc=None).with_format(\"torch\")\n",
    "librivox_dataset['train'] = librivox_dataset['train'].map(augment_dataset, num_proc=None).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a9488b",
   "metadata": {},
   "source": [
    "Merging dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a25e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict()\n",
    "\n",
    "dataset['train'] = concatenate_datasets([common_voice['train'], librivox_dataset['train']])\n",
    "dataset['test'] = common_voice['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94c9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 30.0\n",
    "\n",
    "def is_audio_in_length_range(length):\n",
    "    return length < max_input_length\n",
    "\n",
    "dataset['train'] = dataset['train'].filter(\n",
    "    is_audio_in_length_range,\n",
    "    input_columns=[\"input_length\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d053af",
   "metadata": {},
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "    \n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2c0299",
   "metadata": {},
   "outputs": [],
   "source": [
    "wer_metric = evaluate.load(\"wer\")\n",
    "cer_metric = evaluate.load(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b71913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate with the 'normalised' WER\n",
    "do_normalize_eval = True\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    if do_normalize_eval:\n",
    "        pred_str = [normalizer(pred) for pred in pred_str]\n",
    "        label_str = [normalizer(label) for label in label_str]\n",
    "\n",
    "    wer = 100 * wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = 100 * cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer, \"cer\": cer}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b9996f",
   "metadata": {},
   "source": [
    "# Load pre-trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d45780",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251443d4",
   "metadata": {},
   "source": [
    "# Training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce578f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=10000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=1000,\n",
    "    eval_steps=1000,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,               # push to hub = false\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffb114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3149c55e",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15366085",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speech_recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
